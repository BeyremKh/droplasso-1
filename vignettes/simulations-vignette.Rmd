---
title: "Droplasso vs Glmnet on simulated data"
author: "Beyrem Khalfaoui and Jean-Philippe Vert"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
bibliography: bibli.bib
vignette: >
  %\VignetteIndexEntry{Droplasso vs Glmnet on simulated data}
  %\VignetteEngine{knitr::rmarkdown}
  \usepackage[utf8]{inputenc}---
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, fig.show='hold', fig.width=3.4, fig.height=3.4)
set.seed(4395)
```

# Introduction  

Droplasso is a package that fits a generalized linear model via maximum likelihood regularized by droplasso [@Khalfaoui2018DropLasso], a procedure that combines dropout [@Srivastava2014Dropout] and lasso [@Tibshirani1996Regression] regularizations. Given a training set of samples $x_1,\ldots,x_n\in\mathbb{R}^d$ with labels $y_1,\ldots,y_n\in\mathbb{R}$, the droplasso regularization estimates a linear model $f(x)=w^\top x$ for $x\in\mathbb{R}^d$ by solving:
\begin{equation}
  \min_{w \in \mathbb{R}^d}   \left\{ \frac{1}{n} \sum_{i=1}^{n} \underset{\delta_i \sim B(p)^d}{ \mathbb {E}}  L\left(w,\delta_i  \odot \frac{x_{i,}}{p}  , y_{i} \right)   +  \lambda  \left \| w\right \|_{1} \right\}  \,,
\end{equation}
where $L(w,x,y)$ is a negative log likelihood of a linear model $w$ on a observation $x$ with label $y$, $B(p)$ is the Bernoulli distribution with parameter $p$, and $\odot$ is the entry-wise multiplication of vectors. When $p=1$, each $\delta_i$ is almost surely a vector of $1$'s and droplasso boils down to classical lasso; and when $\lambda=0$, droplasso boils down to dropout.

# Data simulation

Here we illustrate the use of droplasso on simulated data, and compare it to standard dropout and elastic net regularisation. We design a toy simulation to illustrate in particular how corruption by dropout noise impacts the performances of the different methods. The simulation goes as follow : 

- We set the dimension to $d=100$.
- Each sample is a random vector $z\in\mathbb{N}^d$ with entries following a Poisson distribution with parameter $\pi=1$. We introduce correlations between entries by first sampling a Gaussian copula with covariance $\Sigma_d = \mathbf{I}_d + \mathbf{1}_{d}^{\top} \mathbf{1}_d$, then transforming each entry in $[0,1]$ into an integer using the Poisson quantile function.
- The ``true'' model is a logistic model with sparse weight vector $w\in\mathbb{R}^d$ satisfying $w_i=0.05$ for $i=1,\ldots,10$ and $w_i=0$ for $i=11,\ldots,d.$
- Using $w$ as the true underlying model and $z$ as the true observations, we simulate a label $y \sim B( 1/(1+\exp(-w^\top z )) )$  
- We introduce corruption in the samples by dropout events by multiplying entry-wise $z$ with an i.i.d Bernoulli variables $\delta$ with probability $q=0.4$.

Let us simulate $n=100$ samples to form the training set, and $10,000$ samples to test the model:
```{r simulation_setting}
library(mvtnorm)
generate_data <- function(n=100, d=100, d1=10, pi=1, w=0.05, q=0.4) {
  # The samples z
  mu <- rep(0,d)
  Sigma <- (matrix(1, nrow=d, ncol=d)  + diag(d))/2
  rawvars <- rmvnorm(n, mean=mu, sigma=Sigma)
  pvars <- pnorm(rawvars)
  z  <- qpois(pvars, pi)
  # The sparse model w
  w <-c(rep(w,d1),rep(0,d-d1))
  # The labels y
  y <- rbinom(n, 1, 1/(1+exp(-z %*%  w)) )
  # The corrupted samples x
  x <- sapply(1:d, function(i) z[,i] * rbinom(n,1,q))
  return(list(z=z, x=x, y=y, w=w))
}
data_train <- generate_data()
data_test <- generate_data(n=10000)
```

# Comparison of Droplasso and Glmnet
As explained in [@Khalfaoui2018DropLasso], droplasso is related to elastic net regularization [@Zou2005Regularization] that solves:
\begin{equation}
  \min_{w \in \mathbb{R}^d}   \left\{ \frac{1}{n} \sum_{i=1}^{n}  L\left(w, x_i , y_{i} \right)   +  \lambda_{\text{enet}}  \left( \frac{\alpha}{2} \left \| w\right \|_{2}^2 + (\alpha-1) \left \| w\right \|_{1} \right)\right\}  \,.
\end{equation}

```{r glmnet}
library(glmnet)
library(ROCR)
nalpha <- 10
nlambda <- 100
for (i in seq(nalpha)) {
  alpha <- (i-1)/(nalpha-1)
  m_glm <- glmnet(data_train$x, data_train$y, family="binomial", intercept=F, alpha=alpha, standardize = F) # Train glmnet model
  ypred <- (data_test$x) %*% m_glm$beta # predict on the test set
  pred <- sapply(seq(ncol(ypred)), function(j) {prediction(ypred[,j], data_test$y)})
  auc <- unlist(lapply(pred, function(p) {performance(p, "auc")@y.values[[1]]}))
  if (length(auc) < nlambda) { # glmnet did not converge for the last lambda values
    auc <- c(auc, rep(0.5, nlambda-length(auc)))
  }
  if (i == 1) {
    auc_el <- auc
  } else {
    auc_el <- cbind(auc_el, auc)
  }
}
```
# References
